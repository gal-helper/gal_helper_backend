# -*- coding: utf-8 -*-
"""
æ•°æ®åº“åˆå§‹åŒ–è„šæœ¬ - åˆ›å»ºç»Ÿä¸€çš„æ–‡æ¡£è¡¨ç»“æ„
ä»æ—§çš„ 4 ä¸ª vectorstore è¡¨è¿ç§»åˆ°æ–°çš„å•ä¸€ ai_documents è¡¨
"""

import asyncio
import logging
from sqlalchemy import text
from sqlalchemy.ext.asyncio import AsyncSession

from app.models.document import Base, Document, DocumentTagCache, DocumentEmbeddingIndex
from app.core.db import async_db_manager

logger = logging.getLogger(__name__)


async def init_database():
    """åˆå§‹åŒ–æ•°æ®åº“ï¼Œåˆ›å»ºæ‰€æœ‰è¡¨"""
    
    logger.info("ğŸ”„ å¼€å§‹æ•°æ®åº“åˆå§‹åŒ–...")
    
    # 1. è·å–å¼‚æ­¥å¼•æ“
    engine = async_db_manager.async_engine
    if not engine:
        logger.error("âŒ æ•°æ®åº“å¼•æ“æœªåˆå§‹åŒ–")
        return False
    
    try:
        # 2. åˆ›å»ºæ‰€æœ‰è¡¨ï¼ˆä½¿ç”¨ SQLAlchemy æ¨¡å‹ï¼‰
        async with engine.begin() as conn:
            logger.info("ğŸ“ åˆ›å»ºç»Ÿä¸€æ–‡æ¡£è¡¨ç»“æ„...")
            
            # åˆ›å»ºæ‰€æœ‰æ¨¡å‹è¡¨
            await conn.run_sync(Base.metadata.create_all)
            
            logger.info("âœ… è¡¨ç»“æ„åˆ›å»ºå®Œæˆ")
        
        # 3. åˆ›å»ºé¢å¤–çš„ PostgreSQL ç´¢å¼•
        async with AsyncSession(engine) as session:
            logger.info("ğŸ“Š åˆ›å»ºæ•°æ®åº“ç´¢å¼•...")
            
            # å‘é‡ç›¸ä¼¼åº¦æœç´¢ç´¢å¼•ï¼ˆå·²åœ¨æ¨¡å‹ä¸­å®šä¹‰ï¼‰
            # æ ‡ç­¾å¿«é€ŸæŸ¥è¯¢ç´¢å¼•ï¼ˆå·²åœ¨æ¨¡å‹ä¸­å®šä¹‰ï¼‰
            # å…³é”®è¯å…¨æ–‡æœç´¢ç´¢å¼•ï¼ˆå·²åœ¨æ¨¡å‹ä¸­å®šä¹‰ï¼‰
            
            # å¦‚æœéœ€è¦ï¼Œåˆ›å»ºé¢å¤–çš„ GiST ç´¢å¼•ç”¨äºæ›´å¥½çš„æ€§èƒ½
            try:
                await session.execute(text("""
                    CREATE INDEX IF NOT EXISTS ix_document_embedding_gist 
                    ON ai_documents USING gist (embedding)
                """))
                logger.info("âœ… å‘é‡ç´¢å¼•åˆ›å»ºæˆåŠŸ")
            except Exception as e:
                logger.warning(f"âš ï¸  å‘é‡ç´¢å¼•åˆ›å»ºå¤±è´¥: {e}")
        
        # 4. æ£€æŸ¥æ—§è¡¨æ˜¯å¦å­˜åœ¨ï¼ˆç”¨äºè¿ç§»ï¼‰
        logger.info("ğŸ” æ£€æŸ¥æ—§è¡¨æ•°æ®...")
        await check_legacy_tables(engine)
        
        logger.info("âœ… æ•°æ®åº“åˆå§‹åŒ–å®Œæˆ")
        return True
    
    except Exception as e:
        logger.error(f"âŒ æ•°æ®åº“åˆå§‹åŒ–å¤±è´¥: {e}")
        return False


async def check_legacy_tables(engine):
    """
    æ£€æŸ¥æ—§è¡¨æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨åˆ™æç¤ºè¿ç§»
    
    æ—§è¡¨åï¼š
    - document_embeddings
    - vectorstore_resource
    - vectorstore_technical
    - vectorstore_tools
    - vectorstore_news
    """
    
    legacy_tables = [
        "document_embeddings",
        "vectorstore_resource",
        "vectorstore_technical",
        "vectorstore_tools",
        "vectorstore_news",
    ]
    
    async with AsyncSession(engine) as session:
        for table_name in legacy_tables:
            try:
                result = await session.execute(text(f"""
                    SELECT EXISTS (
                        SELECT FROM information_schema.tables 
                        WHERE table_schema = 'public' 
                        AND table_name = '{table_name}'
                    )
                """))
                
                exists = result.scalar()
                if exists:
                    logger.warning(f"âš ï¸  æ£€æµ‹åˆ°æ—§è¡¨: {table_name}")
                    logger.info(f"   å»ºè®®ï¼šå¤‡ä»½æ•°æ®åæ‰§è¡Œè¿ç§»è„šæœ¬")
            
            except Exception as e:
                logger.debug(f"æ£€æŸ¥è¡¨ {table_name} å¤±è´¥: {e}")


async def migrate_from_legacy():
    """
    ä»æ—§è¡¨è¿ç§»æ•°æ®åˆ°æ–°çš„ç»Ÿä¸€è¡¨
    
    è¿ç§»æµç¨‹ï¼š
    1. ä»æ—§ vectorstore è¡¨è¯»å–æ•°æ®
    2. æå–å†…å®¹ã€å‘é‡ã€å…ƒæ•°æ®
    3. ç”Ÿæˆæ–°çš„æ ‡ç­¾ï¼ˆå¦‚æœæœ‰ DeepSeek APIï¼‰
    4. å†™å…¥æ–°çš„ ai_documents è¡¨
    """
    
    logger.info("ğŸ”„ å¼€å§‹æ•°æ®è¿ç§»ï¼ˆå¦‚æœæœ‰æ—§è¡¨ï¼‰...")
    
    engine = async_db_manager.async_engine
    if not engine:
        logger.error("âŒ æ•°æ®åº“å¼•æ“æœªåˆå§‹åŒ–")
        return False
    
    async with AsyncSession(engine) as session:
        try:
            # æ£€æŸ¥æ—§è¡¨æ˜¯å¦å­˜åœ¨
            result = await session.execute(text("""
                SELECT EXISTS (
                    SELECT FROM information_schema.tables 
                    WHERE table_schema = 'public' 
                    AND table_name = 'document_embeddings'
                )
            """))
            
            legacy_exists = result.scalar()
            if not legacy_exists:
                logger.info("âœ… æœªæ£€æµ‹åˆ°æ—§è¡¨ï¼Œæ— éœ€è¿ç§»")
                return True
            
            logger.info("ğŸ“¥ å¼€å§‹è¿ç§»æ—§è¡¨æ•°æ®...")
            
            # è¯»å–æ—§è¡¨ä¸­çš„æ–‡æ¡£
            result = await session.execute(text("""
                SELECT id, document_content, embedding, langchain_metadata 
                FROM document_embeddings
                LIMIT 1000
            """))
            
            rows = result.fetchall()
            logger.info(f"ğŸ“Š è¯»å– {len(rows)} æ¡æ—§è®°å½•")
            
            # è¿ç§»æ•°æ®ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼Œå®Œæ•´è¿ç§»éœ€è¦æ›´å¤æ‚çš„é€»è¾‘ï¼‰
            for row in rows:
                # TODO: åˆ›å»ºæ–° Document å¯¹è±¡å¹¶ä¿å­˜
                pass
            
            logger.info("âœ… æ•°æ®è¿ç§»å®Œæˆ")
            return True
        
        except Exception as e:
            logger.error(f"âŒ è¿ç§»å¤±è´¥: {e}")
            return False


async def create_vector_index():
    """
    åˆ›å»ºå‘é‡ç´¢å¼•ä»¥åŠ å¿«æœç´¢æ€§èƒ½
    
    ä½¿ç”¨ IVFFlat ç´¢å¼•ï¼ˆé€‚åˆå¤§è§„æ¨¡å‘é‡æœç´¢ï¼‰
    """
    
    logger.info("ğŸ“Š åˆ›å»ºå‘é‡ç´¢å¼•...")
    
    engine = async_db_manager.async_engine
    
    async with AsyncSession(engine) as session:
        try:
            # åˆ›å»º pgvector æ‰©å±•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            await session.execute(text("CREATE EXTENSION IF NOT EXISTS vector"))
            
            # åˆ›å»º IVFFlat ç´¢å¼•
            await session.execute(text("""
                CREATE INDEX IF NOT EXISTS idx_embedding_ivf 
                ON ai_documents USING ivfflat (embedding vector_cosine_ops)
                WITH (lists = 100)
            """))
            
            await session.commit()
            logger.info("âœ… IVFFlat å‘é‡ç´¢å¼•åˆ›å»ºæˆåŠŸ")
            
        except Exception as e:
            logger.warning(f"âš ï¸  å‘é‡ç´¢å¼•åˆ›å»ºå¤±è´¥ï¼ˆå¯èƒ½å·²å­˜åœ¨ï¼‰: {e}")


async def create_keyword_index():
    """åˆ›å»ºå…³é”®è¯ç´¢å¼•ä»¥åŠ å¿«å…³é”®è¯æœç´¢"""
    
    logger.info("ğŸ“Š åˆ›å»ºå…³é”®è¯ç´¢å¼•...")
    
    engine = async_db_manager.async_engine
    
    async with AsyncSession(engine) as session:
        try:
            # åˆ›å»º GIN ç´¢å¼•ç”¨äºæ•°ç»„å…³é”®è¯æŸ¥è¯¢
            await session.execute(text("""
                CREATE INDEX IF NOT EXISTS idx_keywords_gin 
                ON ai_documents USING gin (keywords)
            """))
            
            await session.commit()
            logger.info("âœ… å…³é”®è¯ GIN ç´¢å¼•åˆ›å»ºæˆåŠŸ")
            
        except Exception as e:
            logger.warning(f"âš ï¸  å…³é”®è¯ç´¢å¼•åˆ›å»ºå¤±è´¥ï¼ˆå¯èƒ½å·²å­˜åœ¨ï¼‰: {e}")


async def create_tag_index():
    """åˆ›å»ºæ ‡ç­¾ç´¢å¼•ä»¥åŠ å¿«æ ‡ç­¾è¿‡æ»¤"""
    
    logger.info("ğŸ“Š åˆ›å»ºæ ‡ç­¾ç´¢å¼•...")
    
    engine = async_db_manager.async_engine
    
    async with AsyncSession(engine) as session:
        try:
            # åˆ›å»º GIN ç´¢å¼•ç”¨äº JSONB æ ‡ç­¾æŸ¥è¯¢
            await session.execute(text("""
                CREATE INDEX IF NOT EXISTS idx_tags_gin 
                ON ai_documents USING gin (tags)
            """))
            
            await session.commit()
            logger.info("âœ… æ ‡ç­¾ GIN ç´¢å¼•åˆ›å»ºæˆåŠŸ")
            
        except Exception as e:
            logger.warning(f"âš ï¸  æ ‡ç­¾ç´¢å¼•åˆ›å»ºå¤±è´¥ï¼ˆå¯èƒ½å·²å­˜åœ¨ï¼‰: {e}")


async def check_performance_stats():
    """æ£€æŸ¥æ•°æ®åº“æ€§èƒ½ç»Ÿè®¡"""
    
    logger.info("ğŸ“ˆ æ£€æŸ¥æ•°æ®åº“æ€§èƒ½...")
    
    engine = async_db_manager.async_engine
    
    async with AsyncSession(engine) as session:
        try:
            # æ£€æŸ¥è¡¨å¤§å°
            result = await session.execute(text("""
                SELECT 
                    schemaname, tablename, pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size
                FROM pg_tables
                WHERE schemaname = 'public'
                AND tablename LIKE 'ai_%'
                ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC
            """))
            
            rows = result.fetchall()
            if rows:
                logger.info("ğŸ“Š è¡¨å¤§å°ç»Ÿè®¡ï¼š")
                for schema, table, size in rows:
                    logger.info(f"   {table}: {size}")
        
        except Exception as e:
            logger.debug(f"æ€§èƒ½ç»Ÿè®¡æŸ¥è¯¢å¤±è´¥: {e}")


async def main():
    """ä¸»åˆå§‹åŒ–å‡½æ•°"""
    
    # 1. åˆå§‹åŒ–æ•°æ®åº“è¿æ¥
    logger.info("ğŸ”§ åˆå§‹åŒ–æ•°æ®åº“è¿æ¥...")
    await async_db_manager.initialize()
    
    # 2. åˆ›å»ºè¡¨
    success = await init_database()
    
    if success:
        # 3. åˆ›å»ºç´¢å¼•
        await create_vector_index()
        await create_keyword_index()
        await create_tag_index()
        
        # 4. æ£€æŸ¥æ€§èƒ½
        await check_performance_stats()
        
        # 5. è¿ç§»æ—§æ•°æ®ï¼ˆå¯é€‰ï¼‰
        # await migrate_from_legacy()
    
    logger.info("âœ… åˆå§‹åŒ–å®Œæˆ")


if __name__ == "__main__":
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    asyncio.run(main())
